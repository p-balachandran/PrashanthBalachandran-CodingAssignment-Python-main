# ğŸš€ Performance Engineering Assignment

Hi there! ğŸ‘‹ We're thrilled you're interested in joining our team to help build high-quality, scalable systems. This assignment is designed to give you a taste of real-world performance engineering challenges while showcasing your technical skills, problem-solving approach, and engineering mindset.

## âœ¨ What We're Looking For

This assignment will help us understand how you approach performance engineering challenges. We'd love to see your ability to:

- Design and implement automated performance testing
- Simulate realistic load and stress test scenarios
- Analyze system performance data and identify bottlenecks

## ğŸ› ï¸ Let's Get Started!

### Setting Up the Application
First things first, let's get the application up and running:

1. Unzip the provided archive
2. Install dependencies: `npm install`
3. Start the server: `npm start`
4. App URL: http://localhost:5000
5. Credentials: `perftest / perftest`

**Note:** If port 5000 is already in use, try: `PORT=<available_port> npm start`

### Understanding the API
Here's what you'll be working with:
- **POST /login** â€” Authenticates user
- **GET /logout** â€” Logs out user
- **GET /api/search** â€” Search flights (from, to, date)

## ğŸ“‹ What You'll Need to Submit

Here's what we'd like to see in your submission:

- âœ… A JMeter (or other) test plan covering core scenarios
- âœ… A set of test data files
- âœ… Performance test results: Run 2 test scenarios (1 user baseline & 15 users load test, each for 5 minutes) and create a comprehensive metrics analysis report
- âœ… A README with setup, execution, and interpretation guidance
- âœ… Clear documentation (test plan, findings)

## ğŸ“˜ Documentation & Submission Requirements

### ğŸ“ Repository Structure
```
qtt-perf-assignment/
â”œâ”€â”€ README.md
â”œâ”€â”€ jmeter/
â”‚   â”œâ”€â”€ perftestplan.jmx
â”‚   â”œâ”€â”€ test-data/
â”‚   â”‚   â”œâ”€â”€ users.csv
â”‚   â”‚   â””â”€â”€ flights.csv
â”‚   â””â”€â”€ results/
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ test-plan.md
â”‚   â”œâ”€â”€ metrics-analysis.md
â”‚   â””â”€â”€ recommendations.md

```

### ğŸ“„ What We'd Like to See in Your Documentation

#### Test Plan Documentation
- Objectives and strategy
- Tooling used
- Test data explanation

#### Results Analysis
- Key findings
- Charts or summary metrics
- Identified performance issues

#### Recommendations
- Optimization suggestions
- Infrastructure considerations
- Risk and scalability insights

## ğŸ“ A Few Tips

- Focus on performance testing, not functional correctness
- Assume the application is stable and working as expected
- Be clear in your assumptions and make your results actionable
- Feel free to use any additional tools that help improve insights (Grafana, Python scripts, etc.)

Good luck! We're excited to see what you create! ğŸš€ 